{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import e\n",
    "import scipy\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "np.random.seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're going to explore a few different concepts:\n",
    "\n",
    "1. Differential Privacy versus the Laplace Mechanism: a way to sample \"intelligent\" noise (e.g. error) and insert it into the results to reduce privacy loss\n",
    "\n",
    "2. Composition: or the ability to combine differentially private responses to reason about privacy loss (or information gain, depending on how you look at it!)\n",
    "\n",
    "3. How we can calculate a privacy budget using the above concepts! A privacy budget (or privacy accountant) allows us to limit the amount of privacy loss for an individual over the course of several queries.\n",
    "\n",
    "To do so, we will first create an artificial dataset of ages and salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_level_age = 45\n",
    "mid_level_salary = 50000\n",
    "\n",
    "age_scale = 10 #scale represents one standard deviation\n",
    "salary_scale = 10000\n",
    "\n",
    "salaries = [round(np.random.normal(mid_level_salary,salary_scale)) for _ in range(100)]\n",
    "ages = [round(np.random.normal(mid_level_age,age_scale)) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ages, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(salaries, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace Mechanism\n",
    "\n",
    "Let's take a look at the Laplace mechanism for implementing differential privacy and notice the properties it gives us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 0\n",
    "scale = 20\n",
    "\n",
    "x = np.arange(-50., 50., 1)\n",
    "pdf = np.exp(-abs(x-loc)/scale)/(2.*scale)\n",
    "\n",
    "fig,ax= plt.subplots()\n",
    "ax.plot(x, pdf);\n",
    "ax.set_title('Laplace Probability Density Function')\n",
    "ax.set_xlabel('actual number')\n",
    "ax.set_ylabel('probability density');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the Mu and b values, we can see how the distribution changes, and how this might then affect our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = [0, 0, 0, 0, 10]\n",
    "b = [5, 10, 20, 30, 10]\n",
    "\n",
    "x = np.arange(-50., 50., 1)\n",
    "fig,ax= plt.subplots()\n",
    "\n",
    "\n",
    "for mu_val, b_val in zip(mu, b):\n",
    "    pdf = np.exp(-abs(x-mu_val)/b_val)/(2.*b_val)\n",
    "    ax.plot(x, pdf, label='mu=%s b=%s' % (mu_val, b_val))\n",
    "    \n",
    "ax.set_title('Laplace Probability Density Function')\n",
    "ax.set_xlabel('actual number')\n",
    "ax.set_ylabel('probability density')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a very naive differential privacy mechanism, that samples from Laplace and adds the noise to the result. Please note, do not use this with any real data! Instead use a well-known and audited open-source library!\n",
    "\n",
    "NOTE: this is an incorrect usage of laplace, please do not use in a real problem! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1.1\n",
    "\n",
    "def naive_laplace_dp_mechanism(value, epsilon, sensitivity=1):\n",
    "    # Please do not use this function, ever :)\n",
    "    orig_value = value\n",
    "    value =  np.random.laplace(value, sensitivity/epsilon) # more on the default choice of 1/epsilon later!\n",
    "    print(\"Noise: {}\".format(value - orig_value))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_laplace_dp_mechanism(np.mean(ages), epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what if we wanted to figure out the amount of folks working who are older than 40?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_laplace_dp_mechanism(len([a for a in ages if a > 40]), epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it seems here that the mean result for the ages is unsafe. When we look at our age histogram and then at the amount of noise we are using, they appear to be mismatched! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to figure out how to safely add noise, we need to better understand sensitivity!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Sensitivity and Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we want to release data in a differentially privacy way, we need to think about the sensitivity of the result. This is how much one person can change the result of a query. \n",
    "\n",
    "Our error / noise insertion needs to scale with this sensitivity in order for the differential privacy guarantee to hold (i.e. that with one addition or removal to the data, I cannot get \"too much\" more information based on the query result).\n",
    "\n",
    "Sensitivity is how much one person (or privacy unit) can change the results. As you can see, we've been using sensitivity improperly! Let's choose something that is easy to define. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ages = ages + [round(np.random.normal(mid_level_age,age_scale))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_ages) - len(ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our sensitivity is correct for our counting query!\n",
    "\n",
    "But what if we want to use bounds in order to bound a previously unbounded query. We can do so by determining those bounds and then enforcing it on our existing and incoming data. Since I know this dataset is employees who are working, I can choose bounds of 20-70 for the ages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bounds(value, lower_bound, upper_bound):\n",
    "    if value < lower_bound:\n",
    "        return lower_bound\n",
    "    elif value > upper_bound:\n",
    "        return upper_bound\n",
    "    return value\n",
    "\n",
    "bounded_ages = [filter_bounds(age, 20, 70) for age in ages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now appropriately scale the noise, so that we can calculate a safe sum with sensitivity=50. But first we need to figure out how we can run multiple queries and still keep the same guarantees!\n",
    "\n",
    "To give you a visual of the probability density of responses given our current epsilon and sensitivity, check out this graph (or feel free to change the values to fit another query you have in mind!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mu = [0]\n",
    "b = [round(1/1.1, 2)]\n",
    "\n",
    "x = np.arange(-6., 6., 0.1)\n",
    "fig,ax= plt.subplots()\n",
    "\n",
    "\n",
    "for mu_val, b_val in zip(mu, b):\n",
    "    pdf = np.exp(-abs(x-mu_val)/b_val)/(2.*b_val)\n",
    "    ax.plot(x, pdf, label='mu=%s b=%s' % (mu_val, b_val))\n",
    "    \n",
    "ax.set_title('Sensitivity=1, epsilon=1.1')\n",
    "ax.set_xlabel('actual number')\n",
    "ax.set_ylabel('probability density')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composition\n",
    "\n",
    "So how do we reason about how much privacy loss there is when we answer a series of questions about the data? Differential privacy promises that we can track and measure privacy loss, so how do we do this?\n",
    "\n",
    "One amazing property of differential privacy is that the epsilon value (Îµ) is our privacy loss for one particular response and it has the property of being individual to each query and yet composable -- meaning if I answer two queries, I can add their epsilons to calculate the privacy loss!\n",
    "\n",
    "What does this mean in practice? \n",
    "\n",
    "1. Privacy budgets! I can budget my total epsilon appropriately over the course of a certain amount of queries. This means I can detemine how much information gain / privacy loss someone has when given multiple queries across the data.\n",
    "\n",
    "2. The privacy loss is only for the individuals contained in the query response. This means I could also count the budget per individual and stop including those individuals in the responses once their budget has been reached. Of course, this will likely than bias my data as more individuals \"drop out\" when their budgets are reached.\n",
    "\n",
    "3. Depending on what epsilon I come up with, I may want to spend more of it on a particular query than others. So if I know the queries in advance or if I am releasing data all at once, I may want to allocate my budget on a query by query basis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_for_sum = 0.5\n",
    "epsilon_for_count = 0.5\n",
    "\n",
    "summed_ages = naive_laplace_dp_mechanism(np.sum(bounded_ages), epsilon_for_sum, sensitivity=50)\n",
    "count_ages = naive_laplace_dp_mechanism(len(bounded_ages), epsilon_for_count, sensitivity=1)\n",
    "\n",
    "average_age = summed_ages / count_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which means a relative error of..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(average_age - np.mean(ages))/ np.mean(ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "So far we've investigated the ages dataset. Try answering some basic questions about the salaries dataset using the (very simple and slightly broken) Laplace mechanism we've defined here. Some starting points might be:\n",
    "\n",
    "- What is the average salary? \n",
    "- What is the average salary of people over 40?\n",
    "- What is the average salary for people under 40?\n",
    "\n",
    "To do so, you might first want to link the datasets. I have written some example code below to help you get started! \n",
    "\n",
    "_Note_: When you are first experimenting with differential privacy mechanisms and real data, you might end up using the budget just trying to figure out how you might want to release the data. This is not optimal, but it is necessary. The most essential task is to get the differential privacy mechanisms used working properly before releasing data outside of your organization or across trust boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_budget = 1.1\n",
    "\n",
    "# Try tracking your budget as you answer the above. Think about how you spend it wisely!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_dataset = np.column_stack((ages, salaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_40 = linked_dataset[(linked_dataset[:,0] > 40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_employees_over_40 = naive_laplace_dp_mechanism(len(over_40[:,1]), 0.3, sensitivity=1)\n",
    "num_employees_over_40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(over_40[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping my budget honest!\n",
    "my_budget -= 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended Reading\n",
    "\n",
    "- Ted on Privacy's Blog Series on Differential Privacy! https://desfontain.es/privacy/friendly-intro-to-differential-privacy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
